{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hvo8QWN-a9"
   },
   "source": [
    "# Installing Whisper\n",
    "\n",
    "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsJUxc0aRsAf"
   },
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CqtR2Fi5-vP"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import tarfile\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_colwidth = 1000\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IMEkgyagYto"
   },
   "source": [
    "# Loading the Fleurs dataset\n",
    "\n",
    "Select the language of the Fleur dataset to download. Please note that the transcription and translation performance varies widely depending on the language. Appendix D.2 in the paper contains the performance breakdown by language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9cf878888ef0434b9cf5883cb29a4d3f",
      "26369a54159f4f46bb7ba89d0c66f6cb",
      "c78c2f0f2945498a93257ce00a5ee9a7"
     ]
    },
    "id": "L4lPK5106Of2",
    "outputId": "f4b56c91-41fb-4dc3-d905-3d05ce944f87"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "languages = {\"af_za\": \"Afrikaans\", \"am_et\": \"Amharic\", \"ar_eg\": \"Arabic\", \"as_in\": \"Assamese\", \"az_az\": \"Azerbaijani\", \"be_by\": \"Belarusian\", \"bg_bg\": \"Bulgarian\", \"bn_in\": \"Bengali\", \"bs_ba\": \"Bosnian\", \"ca_es\": \"Catalan\", \"cmn_hans_cn\": \"Chinese\", \"cs_cz\": \"Czech\", \"cy_gb\": \"Welsh\", \"da_dk\": \"Danish\", \"de_de\": \"German\", \"el_gr\": \"Greek\", \"en_us\": \"English\", \"es_419\": \"Spanish\", \"et_ee\": \"Estonian\", \"fa_ir\": \"Persian\", \"fi_fi\": \"Finnish\", \"fil_ph\": \"Tagalog\", \"fr_fr\": \"French\", \"gl_es\": \"Galician\", \"gu_in\": \"Gujarati\", \"ha_ng\": \"Hausa\", \"he_il\": \"Hebrew\", \"hi_in\": \"Hindi\", \"hr_hr\": \"Croatian\", \"hu_hu\": \"Hungarian\", \"hy_am\": \"Armenian\", \"id_id\": \"Indonesian\", \"is_is\": \"Icelandic\", \"it_it\": \"Italian\", \"ja_jp\": \"Japanese\", \"jv_id\": \"Javanese\", \"ka_ge\": \"Georgian\", \"kk_kz\": \"Kazakh\", \"km_kh\": \"Khmer\", \"kn_in\": \"Kannada\", \"ko_kr\": \"Korean\", \"lb_lu\": \"Luxembourgish\", \"ln_cd\": \"Lingala\", \"lo_la\": \"Lao\", \"lt_lt\": \"Lithuanian\", \"lv_lv\": \"Latvian\", \"mi_nz\": \"Maori\", \"mk_mk\": \"Macedonian\", \"ml_in\": \"Malayalam\", \"mn_mn\": \"Mongolian\", \"mr_in\": \"Marathi\", \"ms_my\": \"Malay\", \"mt_mt\": \"Maltese\", \"my_mm\": \"Myanmar\", \"nb_no\": \"Norwegian\", \"ne_np\": \"Nepali\", \"nl_nl\": \"Dutch\", \"oc_fr\": \"Occitan\", \"pa_in\": \"Punjabi\", \"pl_pl\": \"Polish\", \"ps_af\": \"Pashto\", \"pt_br\": \"Portuguese\", \"ro_ro\": \"Romanian\", \"ru_ru\": \"Russian\", \"sd_in\": \"Sindhi\", \"sk_sk\": \"Slovak\", \"sl_si\": \"Slovenian\", \"sn_zw\": \"Shona\", \"so_so\": \"Somali\", \"sr_rs\": \"Serbian\", \"sv_se\": \"Swedish\", \"sw_ke\": \"Swahili\", \"ta_in\": \"Tamil\", \"te_in\": \"Telugu\", \"tg_tj\": \"Tajik\", \"th_th\": \"Thai\", \"tr_tr\": \"Turkish\", \"uk_ua\": \"Ukrainian\", \"ur_pk\": \"Urdu\", \"uz_uz\": \"Uzbek\", \"vi_vn\": \"Vietnamese\", \"yo_ng\": \"Yoruba\"}\n",
    "selection = widgets.Dropdown(\n",
    "    options=[(\"Select language\", None), (\"----------\", None)] + sorted([(f\"{v} ({k})\", k) for k, v in languages.items()]),\n",
    "    value=\"es_419\",\n",
    "    description='Language:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eihI6oK6Of2",
    "outputId": "064878a2-569c-4914-e92c-94280ce13dad"
   },
   "outputs": [],
   "source": [
    "lang = selection.value\n",
    "language = languages[lang]\n",
    "\n",
    "assert lang is not None, \"Please select a language\"\n",
    "print(f\"Selected language: {language} ({lang})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuCCB2KYOJCE"
   },
   "outputs": [],
   "source": [
    "def download(url: str, target_path: str):\n",
    "    with urllib.request.urlopen(url) as source, open(target_path, \"wb\") as output:\n",
    "        with tqdm(total=int(source.info().get(\"Content-Length\")), ncols=80, unit='iB', unit_scale=True, unit_divisor=1024) as loop:\n",
    "            while True:\n",
    "                buffer = source.read(8192)\n",
    "                if not buffer:\n",
    "                    break\n",
    "\n",
    "                output.write(buffer)\n",
    "                loop.update(len(buffer))\n",
    "\n",
    "\n",
    "class Fleurs(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap Fleurs and subsample a portion of the dataset as needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang, split=\"test\", subsample_rate=1, device=DEVICE):\n",
    "        url = f\"https://storage.googleapis.com/xtreme_translations/FLEURS102/{lang}.tar.gz\"\n",
    "        tar_path = os.path.expanduser(f\"~/.cache/fleurs/{lang}.tgz\")\n",
    "        os.makedirs(os.path.dirname(tar_path), exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(tar_path):\n",
    "            download(url, tar_path)\n",
    "\n",
    "        all_audio = {}\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            for member in tar.getmembers():\n",
    "                name = member.name\n",
    "                if name.endswith(f\"{split}.tsv\"):\n",
    "                    labels = pd.read_table(tar.extractfile(member), names=(\"id\", \"file_name\", \"raw_transcription\", \"transcription\", \"_\", \"num_samples\", \"gender\"))\n",
    "\n",
    "                if f\"/{split}/\" in name and name.endswith(\".wav\"):\n",
    "                    audio_bytes = tar.extractfile(member).read()\n",
    "                    all_audio[os.path.basename(name)] = wavfile.read(io.BytesIO(audio_bytes))[1]                    \n",
    "\n",
    "        self.labels = labels.to_dict(\"records\")[::subsample_rate]\n",
    "        self.all_audio = all_audio\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        record = self.labels[item]\n",
    "        audio = torch.from_numpy(self.all_audio[record[\"file_name\"]].copy())\n",
    "        text = record[\"transcription\"]\n",
    "        \n",
    "        return (audio, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YcRU5jqNqo2"
   },
   "outputs": [],
   "source": [
    "dataset = Fleurs(lang, subsample_rate=10)  # subsample 10% of the dataset for a quick demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ljocCNuUAde"
   },
   "source": [
    "# Running inference on the dataset using a medium Whisper model\n",
    "\n",
    "The following will take a few minutes to transcribe and translate utterances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PokfNJtOYNu",
    "outputId": "5ace74d4-ff20-4830-fe78-958881ec3905"
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"medium\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F74Yfr696Of5"
   },
   "outputs": [],
   "source": [
    "options = dict(language=language, beam_size=5, best_of=5)\n",
    "transcribe_options = dict(task=\"transcribe\", **options)\n",
    "translate_options = dict(task=\"translate\", **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8cdc3b2a910748e98327462922dc008a",
      "32bd3d1217f24bb8a5e2f853633098d8",
      "dd93a997785a41568a8aba9cf5c0d83a",
      "956741460c504706aa097058dbc6eecf",
      "e4024c536d594ea2be54f471eacd485f",
      "f8eb2f7fc8c1400bb8dc351ea7fa6cfa",
      "76677587cf184477bafcc9d5459b5767",
      "50a75e807f144f438032a8fcdb9cdbe0",
      "dafffcc9b35c4bca95f19079d7c8be60",
      "73a0e8df4bb940bc8feae14e0a66d9c5",
      "ccdbe78adf2f4011946e290c81bd1a51"
     ]
    },
    "id": "7OWTn_KvNk59",
    "outputId": "7fc0731d-fba1-42da-8145-387d280f4bb1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from utils import compute_string_similarity\n",
    "\n",
    "references = []\n",
    "transcriptions = []\n",
    "translations = []\n",
    "distances = []\n",
    "\n",
    "for audio, text in tqdm(dataset):\n",
    "    transcription = model.transcribe(audio, **transcribe_options)[\"text\"]\n",
    "    translation = model.transcribe(audio, **translate_options)[\"text\"]\n",
    "    dist = compute_string_similarity(text, transcription)\n",
    "    \n",
    "    transcriptions.append(transcription)\n",
    "    translations.append(translation)\n",
    "    distances.append(dist)\n",
    "    references.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4nTyynELQ42j",
    "outputId": "c883e334-67bd-462a-89d9-8c011fe42a09",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dict(reference=references, transcription=transcriptions, distance=distances, translation=translations))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83LRfd1plYEb"
   },
   "source": [
    "# Word-level timestamps using attention weights\n",
    "\n",
    "Below, we use the cross-attention weights to determine more granular, word-level timestamps. It uses a set of heuristics and dynamic time warping (DTW) to find the alignment between the audio and the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGtZWNaQlOVC",
    "outputId": "8a03465b-d4c9-40ca-a959-0454a7a8118a"
   },
   "outputs": [],
   "source": [
    "! pip install dtw-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HTv8KmzlZtc",
    "outputId": "63f96356-106d-4404-aa48-885e2ca1f7db"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from dtw import dtw\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqSiARgqlb6X"
   },
   "outputs": [],
   "source": [
    "AUDIO_SAMPLES_PER_TOKEN = whisper.audio.HOP_LENGTH * 2\n",
    "AUDIO_TIME_PER_TOKEN = AUDIO_SAMPLES_PER_TOKEN / whisper.audio.SAMPLE_RATE\n",
    "\n",
    "medfilt_width = 7\n",
    "qk_scale = 1.0\n",
    "\n",
    "tokenizer = get_tokenizer(model.is_multilingual, language=languages[lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTVen0YkldgU"
   },
   "outputs": [],
   "source": [
    "# This part downloads a repackaged version of the Noto Sans font (either CJK or non-CJK)\n",
    "# to render various languages in Matplotlib figures.\n",
    "\n",
    "if languages[lang] in {\"Chinese\", \"Japanese\", \"Korean\"}:\n",
    "    font = \"GoNotoCJKCore.ttf\"\n",
    "else:\n",
    "    font = \"GoNotoCurrent.ttf\"\n",
    "\n",
    "font_release = \"https://github.com/satbyy/go-noto-universal/releases/download/v5.2\"\n",
    "if not os.path.exists(font):\n",
    "    download(f\"{font_release}/{font}\", font)\n",
    "\n",
    "prop = fm.FontProperties(fname=font)\n",
    "props = {'fontproperties': prop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiOFv8X5lhQA"
   },
   "outputs": [],
   "source": [
    "def split_tokens_on_unicode(tokens: torch.Tensor):\n",
    "    words = []\n",
    "    word_tokens = []\n",
    "    current_tokens = []\n",
    "    \n",
    "    for token in tokens.tolist():\n",
    "        current_tokens.append(token)\n",
    "        decoded = tokenizer.decode_with_timestamps(current_tokens)\n",
    "        if \"\\ufffd\" not in decoded:\n",
    "            words.append(decoded)\n",
    "            word_tokens.append(current_tokens)\n",
    "            current_tokens = []\n",
    "    \n",
    "    return words, word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkhsL9xUmHjt"
   },
   "outputs": [],
   "source": [
    "def split_tokens_on_spaces(tokens: torch.Tensor):\n",
    "    subwords, subword_tokens_list = split_tokens_on_unicode(tokens)\n",
    "    words = []\n",
    "    word_tokens = []\n",
    "    \n",
    "    for subword, subword_tokens in zip(subwords, subword_tokens_list):\n",
    "        special = subword_tokens[0] >= tokenizer.eot\n",
    "        with_space = subword.startswith(\" \")\n",
    "        punctuation = subword.strip() in string.punctuation\n",
    "        if special or with_space or punctuation:\n",
    "            words.append(subword)\n",
    "            word_tokens.append(subword_tokens)\n",
    "        else:\n",
    "            words[-1] = words[-1] + subword\n",
    "            word_tokens[-1].extend(subword_tokens)\n",
    "    \n",
    "    return words, word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQOl_4TSmIgB"
   },
   "outputs": [],
   "source": [
    "if languages[lang] in {\"Chinese\", \"Japanese\", \"Thai\", \"Lao\", \"Myanmar\"}:\n",
    "    # These languages don't typically use spaces, so it is difficult to split words\n",
    "    # without morpheme analysis. Here, we instead split words at any\n",
    "    # position where the tokens are decoded as valid unicode points\n",
    "    split_tokens = split_tokens_on_unicode\n",
    "else:\n",
    "    split_tokens = split_tokens_on_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGwrymCo5SUe"
   },
   "outputs": [],
   "source": [
    "# install hooks on the cross attention layers to retrieve the attention weights\n",
    "QKs = [None] * model.dims.n_text_layer\n",
    "\n",
    "for i, block in enumerate(model.decoder.blocks):\n",
    "    block.cross_attn.register_forward_hook(\n",
    "        lambda _, ins, outs, index=i: QKs.__setitem__(index, outs[-1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "SOT sequence can include language and task\n",
    "\n",
    "'<|startoftranscript|><|es|><|transcribe|>'\n",
    "\n",
    "tokenizer.eot = '<|endoftext|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6q-mBLVNmJ1i",
    "outputId": "75aba6d9-389a-4959-b0e5-452424411055"
   },
   "outputs": [],
   "source": [
    "# for the first 10 examples in the dataset\n",
    "for (audio, label), transcription in zip(dataset, transcriptions[:10]):\n",
    "    print(transcription)\n",
    "  \n",
    "    duration = len(audio)\n",
    "    mel = whisper.log_mel_spectrogram(whisper.pad_or_trim(audio)).cuda()\n",
    "    tokens = torch.tensor(\n",
    "        [\n",
    "            *tokenizer.sot_sequence,\n",
    "            tokenizer.timestamp_begin,\n",
    "        ] + tokenizer.encode(transcription) + [\n",
    "            tokenizer.timestamp_begin + duration // AUDIO_SAMPLES_PER_TOKEN,\n",
    "            tokenizer.eot,\n",
    "        ]\n",
    "    ).cuda()\n",
    "    with torch.no_grad():\n",
    "        logits = model(mel.unsqueeze(0), tokens.unsqueeze(0))\n",
    "\n",
    "    weights = torch.cat(QKs)  # layers * heads * tokens * frames    \n",
    "    weights = weights[:, :, :, : duration // AUDIO_SAMPLES_PER_TOKEN].cpu()\n",
    "    weights = median_filter(weights, (1, 1, 1, medfilt_width))\n",
    "    weights = torch.tensor(weights * qk_scale).softmax(dim=-1)\n",
    "    \n",
    "    w = weights / weights.norm(dim=-2, keepdim=True)\n",
    "    matrix = w[-6:].mean(axis=(0, 1))\n",
    "\n",
    "    alignment = dtw(-matrix.double().numpy())\n",
    "\n",
    "    jumps = np.pad(np.diff(alignment.index1s), (1, 0), constant_values=1).astype(bool)\n",
    "    jump_times = alignment.index2s[jumps] * AUDIO_TIME_PER_TOKEN\n",
    "    words, word_tokens = split_tokens(tokens)\n",
    "\n",
    "    # display the normalized attention weights and the alignment\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(matrix, aspect=\"auto\")\n",
    "    plt.plot(alignment.index2s, alignment.index1s, color=\"red\")\n",
    "\n",
    "    xticks = np.arange(0, matrix.shape[1], 1 / AUDIO_TIME_PER_TOKEN)\n",
    "    xticklabels = (xticks * AUDIO_TIME_PER_TOKEN).round().astype(np.int32) \n",
    "    plt.xticks(xticks, xticklabels)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    \n",
    "    # display tokens and words as tick labels\n",
    "    ylims = plt.gca().get_ylim()\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params('both', length=0, width=0, which='minor', pad=6)\n",
    "\n",
    "    ax.yaxis.set_ticks_position(\"left\")\n",
    "    ax.yaxis.set_label_position(\"left\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_ylim(ylims)\n",
    "\n",
    "    major_ticks = [-0.5]\n",
    "    minor_ticks = []\n",
    "    current_y = 0\n",
    "    \n",
    "    for word, word_token in zip(words, word_tokens):\n",
    "        minor_ticks.append(current_y + len(word_token) / 2 - 0.5)\n",
    "        current_y += len(word_token)\n",
    "        major_ticks.append(current_y - 0.5)\n",
    "        \n",
    "    ax.yaxis.set_minor_locator(ticker.FixedLocator(minor_ticks))\n",
    "    ax.yaxis.set_minor_formatter(ticker.FixedFormatter(words))\n",
    "    ax.set_yticks(major_ticks)\n",
    "    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    \n",
    "    for label in ax.get_yminorticklabels():\n",
    "        label.set_fontproperties(prop)\n",
    "\n",
    "    plt.ylabel(\"Words\")\n",
    "    plt.show()\n",
    "\n",
    "    # display the word-level timestamps in a table\n",
    "    word_boundaries = np.pad(np.cumsum([len(t) for t in word_tokens[:-1]]), (1, 0))\n",
    "    begin_times = jump_times[word_boundaries[:-1]]\n",
    "    end_times = jump_times[word_boundaries[1:]]\n",
    "\n",
    "    data = [\n",
    "        dict(word=word, begin=begin, end=end)\n",
    "        for word, begin, end in zip(words[:-1], begin_times, end_times)\n",
    "        if not word.startswith(\"<|\") and word.strip() not in \".,!?、。\"\n",
    "    ]\n",
    "\n",
    "    display(pd.DataFrame(data))\n",
    "    display(HTML(\"<hr>\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26369a54159f4f46bb7ba89d0c66f6cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32bd3d1217f24bb8a5e2f853633098d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8eb2f7fc8c1400bb8dc351ea7fa6cfa",
      "placeholder": "​",
      "style": "IPY_MODEL_76677587cf184477bafcc9d5459b5767",
      "value": "100%"
     }
    },
    "50a75e807f144f438032a8fcdb9cdbe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73a0e8df4bb940bc8feae14e0a66d9c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76677587cf184477bafcc9d5459b5767": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cdc3b2a910748e98327462922dc008a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32bd3d1217f24bb8a5e2f853633098d8",
       "IPY_MODEL_dd93a997785a41568a8aba9cf5c0d83a",
       "IPY_MODEL_956741460c504706aa097058dbc6eecf"
      ],
      "layout": "IPY_MODEL_e4024c536d594ea2be54f471eacd485f"
     }
    },
    "956741460c504706aa097058dbc6eecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73a0e8df4bb940bc8feae14e0a66d9c5",
      "placeholder": "​",
      "style": "IPY_MODEL_ccdbe78adf2f4011946e290c81bd1a51",
      "value": " 39/39 [03:30&lt;00:00,  6.04s/it]"
     }
    },
    "9cf878888ef0434b9cf5883cb29a4d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "Select language",
       "----------",
       "Afrikaans (af_za)",
       "Amharic (am_et)",
       "Arabic (ar_eg)",
       "Armenian (hy_am)",
       "Assamese (as_in)",
       "Azerbaijani (az_az)",
       "Belarusian (be_by)",
       "Bengali (bn_in)",
       "Bosnian (bs_ba)",
       "Bulgarian (bg_bg)",
       "Catalan (ca_es)",
       "Chinese (cmn_hans_cn)",
       "Croatian (hr_hr)",
       "Czech (cs_cz)",
       "Danish (da_dk)",
       "Dutch (nl_nl)",
       "English (en_us)",
       "Estonian (et_ee)",
       "Finnish (fi_fi)",
       "French (fr_fr)",
       "Galician (gl_es)",
       "Georgian (ka_ge)",
       "German (de_de)",
       "Greek (el_gr)",
       "Gujarati (gu_in)",
       "Hausa (ha_ng)",
       "Hebrew (he_il)",
       "Hindi (hi_in)",
       "Hungarian (hu_hu)",
       "Icelandic (is_is)",
       "Indonesian (id_id)",
       "Italian (it_it)",
       "Japanese (ja_jp)",
       "Javanese (jv_id)",
       "Kannada (kn_in)",
       "Kazakh (kk_kz)",
       "Khmer (km_kh)",
       "Korean (ko_kr)",
       "Lao (lo_la)",
       "Latvian (lv_lv)",
       "Lingala (ln_cd)",
       "Lithuanian (lt_lt)",
       "Luxembourgish (lb_lu)",
       "Macedonian (mk_mk)",
       "Malay (ms_my)",
       "Malayalam (ml_in)",
       "Maltese (mt_mt)",
       "Maori (mi_nz)",
       "Marathi (mr_in)",
       "Mongolian (mn_mn)",
       "Myanmar (my_mm)",
       "Nepali (ne_np)",
       "Norwegian (nb_no)",
       "Occitan (oc_fr)",
       "Pashto (ps_af)",
       "Persian (fa_ir)",
       "Polish (pl_pl)",
       "Portuguese (pt_br)",
       "Punjabi (pa_in)",
       "Romanian (ro_ro)",
       "Russian (ru_ru)",
       "Serbian (sr_rs)",
       "Shona (sn_zw)",
       "Sindhi (sd_in)",
       "Slovak (sk_sk)",
       "Slovenian (sl_si)",
       "Somali (so_so)",
       "Spanish (es_419)",
       "Swahili (sw_ke)",
       "Swedish (sv_se)",
       "Tagalog (fil_ph)",
       "Tajik (tg_tj)",
       "Tamil (ta_in)",
       "Telugu (te_in)",
       "Thai (th_th)",
       "Turkish (tr_tr)",
       "Ukrainian (uk_ua)",
       "Urdu (ur_pk)",
       "Uzbek (uz_uz)",
       "Vietnamese (vi_vn)",
       "Welsh (cy_gb)",
       "Yoruba (yo_ng)"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Language:",
      "description_tooltip": null,
      "disabled": false,
      "index": 39,
      "layout": "IPY_MODEL_26369a54159f4f46bb7ba89d0c66f6cb",
      "style": "IPY_MODEL_c78c2f0f2945498a93257ce00a5ee9a7"
     }
    },
    "c78c2f0f2945498a93257ce00a5ee9a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccdbe78adf2f4011946e290c81bd1a51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dafffcc9b35c4bca95f19079d7c8be60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd93a997785a41568a8aba9cf5c0d83a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50a75e807f144f438032a8fcdb9cdbe0",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dafffcc9b35c4bca95f19079d7c8be60",
      "value": 39
     }
    },
    "e4024c536d594ea2be54f471eacd485f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8eb2f7fc8c1400bb8dc351ea7fa6cfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}